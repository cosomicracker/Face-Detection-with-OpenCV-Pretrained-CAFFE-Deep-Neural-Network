# Import libraries
import os
import cv2
import sys
import matplotlib.pyplot as plt

from zipfile import ZipFile
from urllib.request import urlretrieve

%matplotlib inline


# ==================-Downloading Assets-==================
def download_and_unzip(url, save_path):
  print(f"Downloading and extracting...", end="")

  urlretrieve(url, save_path)

  try:
    with ZipFile(save_path) as z:
      z.extractall(os.path.split(save_path)[0])

    print("Done")

  except Exception as e:
    print("/nInvalid file.", e)

# Find assets from OpenCV dropbox
URL = r"https://www.dropbox.com/s/efitgt363ada95a/opencv_bootcamp_assets_12.zip?dl=1"

asset_zip_path = os.path.join(os.getcwd(), f"opencv_bootcamp_assets_12.zip")

if not os.path.exists(asset_zip_path):
  download_and_unzip(URL, asset_zip_path)
# ========================================================


protoFile = "deploy.prototxt"
weightsFile = "res10_300x300_ssd_iter_140000_fp16.caffemodel"

# Model parameters
in_width = 300
in_height = 300
mean = [104, 117, 123]
conf_threshold = 0.7

# Create subplot system
plt.figure(figsize=[16, 7])

net = cv2.dnn.readNetFromCaffe(protoFile, weightsFile)

def detect_frame(frame, frameID):
  frame_height = frame.shape[0]
  frame_width = frame.shape[1]

  # Create a 4D blob from a frame
  blob = cv2.dnn.blobFromImage(frame, 1.0, (in_width, in_height), mean, swapRB=False, crop=False)
  # Run the model
  net.setInput(blob)
  detections = net.forward()

  for i in range(detections.shape[2]):
    confidence = detections[0, 0, i, 2]
    if confidence > conf_threshold:
      x_top_left = int(detections[0, 0, i, 3] * frame_width)
      y_top_left = int(detections[0, 0, i, 4] * frame_height)
      x_bottom_right = int(detections[0, 0, i, 5] * frame_width)
      y_bottom_right = int(detections[0, 0, i, 6] * frame_height)

      cv2.rectangle(frame, (x_top_left, y_top_left), (x_bottom_right, y_bottom_right), (0, 255, 0), 4)
      label = "Confidence: %.4f" % confidence
      label_size, base_line = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)

      cv2.rectangle(
          frame,
          (x_top_left, y_top_left - label_size[1]),
          (x_top_left + label_size[0], y_top_left + base_line),
          (255, 255, 255),
          cv2.FILLED)
      cv2.putText(frame, label, (x_top_left, y_top_left), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0))

  t, _ = net.getPerfProfile()
  label = "Inference time: %.2f ms" % (t * 1000.0 / cv2.getTickFrequency())
  cv2.putText(frame, label, (0, 15), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0))
  frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) # matplotlib uses RGB channels while cv2 and the DNN use BGR
  plt.subplot(131 + int(frameID)); plt.imshow(frame_rgb)

# Download an image and run detection forward pass
img = cv2.imread("elan_sleazebaggano.jpeg") # DOWNLOAD AND SUBSTITUTE YOUR OWN IMAGES
detect_frame(img, 0)

# Image 2
img = cv2.imread("elon_musk.jpeg") # DOWNLOAD AND SUBSTITUTE YOUR OWN IMAGES
detect_frame(img, 1)
